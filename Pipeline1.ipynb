{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6266bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial import Delaunay\n",
    "import mediapipe as mp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0915cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.3,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dd41dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Landmark Indices ---\n",
    "left_brow_idx = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46]\n",
    "right_brow_idx = [300, 293, 334, 296, 336, 285, 295, 282, 283, 276]\n",
    "inner_brow_idx = [63, 293]\n",
    "brow_landmarks_idx = list(set(left_brow_idx + right_brow_idx + inner_brow_idx))\n",
    "\n",
    "left_cheek_idx = [205, 206, 216, 204, 207, 114, 115, 116, 213, 214, 215]\n",
    "right_cheek_idx = [425, 426, 436, 424, 427, 343, 344, 345, 433, 434, 435]\n",
    "cheek_landmarks_idx = list(set(left_cheek_idx + right_cheek_idx))\n",
    "\n",
    "left_eye_idx = [33, 160, 158, 133, 153, 144, 145, 159]\n",
    "right_eye_idx = [362, 385, 387, 263, 373, 374, 380, 386]\n",
    "outer_eye_idx = [33, 133, 362, 263]\n",
    "eye_landmarks_idx = list(set(left_eye_idx + right_eye_idx + outer_eye_idx))\n",
    "\n",
    "jaw_landmarks_idx = [152, 176, 136, 172, 397, 365, 366, 379, 400, 378, 377]\n",
    "\n",
    "lip_landmarks_idx = [13, 14, 37, 39, 40, 61, 78, 80, 81, 82, 84, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270, 291, 308, 310, 311, 312, 314, 321, 324, 375, 402, 405, 409, 415]\n",
    "\n",
    "mouth_landmarks_idx = [13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270, 291, 308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415]\n",
    "\n",
    "# --- LEFT / RIGHT Surface Vector Splits ---\n",
    "left_brow_idx_surface = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46]\n",
    "right_brow_idx_surface = [300, 293, 334, 296, 336, 285, 295, 282, 283, 276]\n",
    "\n",
    "left_cheek_idx_surface = [205, 206, 216, 204, 207, 114, 115, 116]\n",
    "right_cheek_idx_surface = [425, 426, 436, 424, 427, 343, 344, 345]\n",
    "\n",
    "left_eye_idx_surface = [33, 160, 158, 133, 153, 144, 145, 159]\n",
    "right_eye_idx_surface = [362, 385, 387, 263, 373, 374, 380, 386]\n",
    "\n",
    "left_jaw_idx_surface = [152, 176, 136, 172]\n",
    "right_jaw_idx_surface = [397, 365, 366, 379, 400, 378, 377]\n",
    "\n",
    "left_lip_idx_surface = [61, 78, 80, 81, 82, 84, 91, 95]\n",
    "right_lip_idx_surface = [291, 308, 310, 311, 312, 314, 321, 324]\n",
    "\n",
    "left_mouth_idx_surface = [61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 17]\n",
    "right_mouth_idx_surface = [291, 308, 310, 311, 312, 314, 317, 318, 321, 324, 375]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23dd2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Buffers ---\n",
    "buffer_size = 10\n",
    "brow_raise_buffer = deque(maxlen=buffer_size)\n",
    "brow_left_raise_buffer = deque(maxlen=buffer_size)\n",
    "brow_right_raise_buffer = deque(maxlen=buffer_size)\n",
    "brow_inner_raise_buffer = deque(maxlen=buffer_size)\n",
    "brow_vel_buffer = deque(maxlen=buffer_size)\n",
    "brow_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "brow_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "cheek_raise_buffer = deque(maxlen=buffer_size)\n",
    "cheek_vel_buffer = deque(maxlen=buffer_size)\n",
    "cheek_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "cheek_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "eye_ratio_buffer = deque(maxlen=buffer_size)\n",
    "eye_vel_buffer = deque(maxlen=buffer_size)\n",
    "blink_buffer = deque(maxlen=30)\n",
    "eye_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "eye_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "jaw_open_buffer = deque(maxlen=buffer_size)\n",
    "jaw_vel_buffer = deque(maxlen=buffer_size)\n",
    "jaw_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "jaw_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "lips_open_buffer = deque(maxlen=buffer_size)\n",
    "lips_vel_buffer = deque(maxlen=buffer_size)\n",
    "lips_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "lips_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "mouth_open_buffer = deque(maxlen=buffer_size)\n",
    "mouth_vel_buffer = deque(maxlen=buffer_size)\n",
    "mouth_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "mouth_surface_dir_buffer = deque(maxlen=buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90c7eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global ---\n",
    "frame_global = None\n",
    "features_global = {\n",
    "    'Eye': {}, 'Brow': {}, 'Cheek': {}, 'Mouth': {}, 'Lips': {}, 'Jaw': {}\n",
    "}\n",
    "prev_landmarks_global = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b72bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Surface Vector Split Function ---\n",
    "def compute_surface_vectors_split(landmarks, prev_landmarks, left_idx, right_idx):\n",
    "    if prev_landmarks is None or landmarks is None:\n",
    "        zero = {'vectors': np.array([]), 'positions': [], 'norms': np.array([]), 'mean_mag': 0.0, 'var': 0.0, 'angle': 0.0}\n",
    "        return {'left': zero, 'right': zero}\n",
    "\n",
    "    def process_side(idx_list):\n",
    "        if not idx_list:\n",
    "            return {'vectors': np.array([]), 'positions': [], 'norms': np.array([]), 'mean_mag': 0.0, 'var': 0.0, 'angle': 0.0}\n",
    "\n",
    "        curr_pos = []\n",
    "        prev_pos = []\n",
    "        for idx in idx_list:\n",
    "            if idx >= len(landmarks) or idx >= len(prev_landmarks):\n",
    "                continue\n",
    "            curr_pos.append(np.array(landmarks[idx]))\n",
    "            prev_pos.append(np.array(prev_landmarks[idx]))\n",
    "\n",
    "        if len(curr_pos) < 3:\n",
    "            return {'vectors': np.array([]), 'positions': [], 'norms': np.array([]), 'mean_mag': 0.0, 'var': 0.0, 'angle': 0.0}\n",
    "\n",
    "        points2d = np.array([p[:2] for p in curr_pos])\n",
    "\n",
    "        try:\n",
    "            tri = Delaunay(points2d)\n",
    "        except:\n",
    "            return {'vectors': np.array([]), 'positions': [], 'norms': np.array([]), 'mean_mag': 0.0, 'var': 0.0, 'angle': 0.0}\n",
    "\n",
    "        triangle_norms = []\n",
    "        triangle_vectors = []\n",
    "        triangle_areas = []\n",
    "\n",
    "        for simplex in tri.simplices:\n",
    "            i1, i2, i3 = simplex\n",
    "            v1 = curr_pos[i1] - prev_pos[i1]\n",
    "            v2 = curr_pos[i2] - prev_pos[i2]\n",
    "            v3 = curr_pos[i3] - prev_pos[i3]\n",
    "            mean_v = (v1 + v2 + v3) / 3\n",
    "            norm = np.linalg.norm(mean_v)\n",
    "            triangle_norms.append(norm)\n",
    "            if norm > 1e-6:\n",
    "                triangle_vectors.append(mean_v / norm)\n",
    "            else:\n",
    "                triangle_vectors.append(mean_v)\n",
    "            area = 0.5 * np.abs(np.cross(points2d[i2] - points2d[i1], points2d[i3] - points2d[i1]))\n",
    "            triangle_areas.append(area)\n",
    "\n",
    "        triangle_norms = np.array(triangle_norms)\n",
    "        mean_mag = np.mean(triangle_norms) if len(triangle_norms) > 0 else 0.0\n",
    "        var = np.var(triangle_norms) if len(triangle_norms) > 0 else 0.0\n",
    "\n",
    "        angle = 0.0\n",
    "        if triangle_vectors and triangle_areas:\n",
    "            weighted_vectors = np.array(triangle_vectors) * np.array(triangle_areas)[:, np.newaxis]\n",
    "            avg = np.sum(weighted_vectors[:, :2], axis=0) / np.sum(triangle_areas)\n",
    "            n = np.linalg.norm(avg)\n",
    "            if n > 1e-6:\n",
    "                angle = np.arctan2(avg[1], avg[0])\n",
    "\n",
    "        vectors = np.array(triangle_vectors) if triangle_vectors else np.array([])\n",
    "        norms = triangle_norms\n",
    "        positions = [np.mean([curr_pos[i] for i in s], axis=0) for s in tri.simplices]\n",
    "\n",
    "        return {'vectors': vectors, 'positions': positions, 'norms': norms, 'mean_mag': mean_mag, 'var': var, 'angle': angle}\n",
    "\n",
    "    return {'left': process_side(left_idx), 'right': process_side(right_idx)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64ba162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BROW ---\n",
    "def compute_brow_features(landmarks, prev_landmarks):\n",
    "    if landmarks is None: return {}\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    norm_landmarks = [np.array(lm) - nose_tip for lm in landmarks]\n",
    "\n",
    "    left_brow_ys = [norm_landmarks[i][1] for i in left_brow_idx]\n",
    "    right_brow_ys = [norm_landmarks[i][1] for i in right_brow_idx]\n",
    "    inner_brow_ys = [norm_landmarks[i][1] for i in inner_brow_idx]\n",
    "\n",
    "    left_raise = -np.mean(left_brow_ys)\n",
    "    right_raise = -np.mean(right_brow_ys)\n",
    "    inner_raise = -np.mean(inner_brow_ys)\n",
    "    overall_raise = (left_raise + right_raise) / 2\n",
    "\n",
    "    brow_left_raise_buffer.append(left_raise)\n",
    "    brow_right_raise_buffer.append(right_raise)\n",
    "    brow_inner_raise_buffer.append(inner_raise)\n",
    "    brow_raise_buffer.append(overall_raise)\n",
    "\n",
    "    left_stats = [np.mean(brow_left_raise_buffer), np.std(brow_left_raise_buffer)] if len(brow_left_raise_buffer) > 1 else [0, 0]\n",
    "    right_stats = [np.mean(brow_right_raise_buffer), np.std(brow_right_raise_buffer)] if len(brow_right_raise_buffer) > 1 else [0, 0]\n",
    "    inner_stats = [np.mean(brow_inner_raise_buffer), np.std(brow_inner_raise_buffer)] if len(brow_inner_raise_buffer) > 1 else [0, 0]\n",
    "\n",
    "    brow_vel = abs(overall_raise - brow_raise_buffer[-2]) if len(brow_raise_buffer) > 1 else 0\n",
    "    brow_vel_buffer.append(brow_vel)\n",
    "    vel_stats = [np.mean(brow_vel_buffer), np.std(brow_vel_buffer)] if len(brow_vel_buffer) > 1 else [0, 0]\n",
    "    rapid_count = len(find_peaks(list(brow_vel_buffer), distance=2)[0]) if len(brow_vel_buffer) > 1 else 0\n",
    "\n",
    "    micro_var = np.var(brow_raise_buffer) if len(brow_raise_buffer) > 1 else 0.0\n",
    "    freq_mean = np.mean(np.abs(fft(list(brow_raise_buffer)))[:buffer_size//2]) if len(brow_raise_buffer) == buffer_size else 0.0\n",
    "    peak_freq = np.max(np.abs(fft(list(brow_raise_buffer)))[:buffer_size//2]) if len(brow_raise_buffer) == buffer_size else 0.0\n",
    "\n",
    "    brow_asym = abs(left_raise - right_raise)\n",
    "    inner_asym = abs(norm_landmarks[63][1] - norm_landmarks[293][1])\n",
    "    asym_diffs = np.abs(np.array(brow_left_raise_buffer) - np.array(brow_right_raise_buffer))\n",
    "    temp_asym_var = np.var(asym_diffs) if len(asym_diffs) > 1 else 0.0\n",
    "\n",
    "    surface = compute_surface_vectors_split(landmarks, prev_landmarks, left_brow_idx_surface, right_brow_idx_surface)\n",
    "    left, right = surface['left'], surface['right']\n",
    "\n",
    "    brow_surface_var_buffer.append({'left': left['var'], 'right': right['var']})\n",
    "    brow_surface_dir_buffer.append({'left': left['angle'], 'right': right['angle']})\n",
    "\n",
    "    left_vars = [x['left'] for x in list(brow_surface_var_buffer)[-10:]]\n",
    "    right_vars = [x['right'] for x in list(brow_surface_var_buffer)[-10:]]\n",
    "    left_angles = [x['left'] for x in list(brow_surface_dir_buffer)[-10:]]\n",
    "    right_angles = [x['right'] for x in list(brow_surface_dir_buffer)[-10:]]\n",
    "\n",
    "    var_stats_l = [np.mean(left_vars), np.std(left_vars), np.min(left_vars), np.max(left_vars)] if left_vars else [0]*4\n",
    "    var_stats_r = [np.mean(right_vars), np.std(right_vars), np.min(right_vars), np.max(right_vars)] if right_vars else [0]*4\n",
    "    dir_stats_l = [np.mean(left_angles), np.std(left_angles)] if len(left_angles) > 1 else [0, 0]\n",
    "    dir_stats_r = [np.mean(right_angles), np.std(right_angles)] if len(right_angles) > 1 else [0, 0]\n",
    "\n",
    "    return {\n",
    "        'Brow micro-expression variance mean': micro_var,\n",
    "        'Brow micro-expression rapid changes count': rapid_count,\n",
    "        'Brow velocity (mean)': vel_stats[0],\n",
    "        'Brow velocity (std)': vel_stats[1],\n",
    "        'Right brow raise (mean)': right_stats[0],\n",
    "        'Right brow raise (std)': right_stats[1],\n",
    "        'Left brow raise (mean)': left_stats[0],\n",
    "        'Left brow raise (std)': left_stats[1],\n",
    "        'Inner brow raise (mean)': inner_stats[0],\n",
    "        'Inner brow raise (std)': inner_stats[1],\n",
    "        'Brow asymmetry (mean)': brow_asym,\n",
    "        'Temporal brow asymmetry variance': temp_asym_var,\n",
    "        'Brow frequency mean': freq_mean,\n",
    "        'Brow peak frequency': peak_freq,\n",
    "\n",
    "        'Left surface vector magnitude mean': left['mean_mag'],\n",
    "        'Left surface variance (current)': left['var'],\n",
    "        'Left surface variance mean': var_stats_l[0],\n",
    "        'Left surface variance std': var_stats_l[1],\n",
    "        'Left surface variance min': var_stats_l[2],\n",
    "        'Left surface variance max': var_stats_l[3],\n",
    "        'Left surface dominant angle mean': dir_stats_l[0],\n",
    "        'Left surface dominant angle std': dir_stats_l[1],\n",
    "\n",
    "        'Right surface vector magnitude mean': right['mean_mag'],\n",
    "        'Right surface variance (current)': right['var'],\n",
    "        'Right surface variance mean': var_stats_r[0],\n",
    "        'Right surface variance std': var_stats_r[1],\n",
    "        'Right surface variance min': var_stats_r[2],\n",
    "        'Right surface variance max': var_stats_r[3],\n",
    "        'Right surface dominant angle mean': dir_stats_r[0],\n",
    "        'Right surface dominant angle std': dir_stats_r[1],\n",
    "    }\n",
    "\n",
    "\n",
    "# --- CHEEK ---\n",
    "def compute_cheek_features(landmarks, prev_landmarks):\n",
    "    if landmarks is None: return {}\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    norm_landmarks = [np.array(lm) - nose_tip for lm in landmarks]\n",
    "\n",
    "    left_ys = [norm_landmarks[i][1] for i in left_cheek_idx if i < len(norm_landmarks)]\n",
    "    left_xs = [norm_landmarks[i][0] for i in left_cheek_idx if i < len(norm_landmarks)]\n",
    "    right_ys = [norm_landmarks[i][1] for i in right_cheek_idx if i < len(norm_landmarks)]\n",
    "    right_xs = [norm_landmarks[i][0] for i in right_cheek_idx if i < len(norm_landmarks)]\n",
    "\n",
    "    left_raise = -np.mean(left_ys) + np.mean(left_xs) if left_ys else 0\n",
    "    right_raise = -np.mean(right_ys) + np.mean(right_xs) if right_ys else 0\n",
    "    overall = (left_raise + right_raise) / 2\n",
    "\n",
    "    cheek_raise_buffer.append(overall)\n",
    "    stats = [np.mean(cheek_raise_buffer), np.std(cheek_raise_buffer)] if len(cheek_raise_buffer) > 1 else [0, 0]\n",
    "    vel = abs(overall - cheek_raise_buffer[-2]) if len(cheek_raise_buffer) > 1 else 0\n",
    "    cheek_vel_buffer.append(vel)\n",
    "    vel_stats = [np.mean(cheek_vel_buffer), np.std(cheek_vel_buffer)] if len(cheek_vel_buffer) > 1 else [0, 0]\n",
    "    rapid = len(find_peaks(list(cheek_vel_buffer), distance=2)[0]) if len(cheek_vel_buffer) > 1 else 0\n",
    "    var = np.var(cheek_raise_buffer) if len(cheek_raise_buffer) > 1 else 0\n",
    "    freq = np.mean(np.abs(fft(list(cheek_raise_buffer)))[:buffer_size//2]) if len(cheek_raise_buffer) == buffer_size else 0\n",
    "\n",
    "    asym = abs(left_raise - right_raise)\n",
    "    surface = compute_surface_vectors_split(landmarks, prev_landmarks, left_cheek_idx_surface, right_cheek_idx_surface)\n",
    "    l, r = surface['left'], surface['right']\n",
    "    cheek_surface_var_buffer.append({'left': l['var'], 'right': r['var']})\n",
    "    cheek_surface_dir_buffer.append({'left': l['angle'], 'right': r['angle']})\n",
    "\n",
    "    lv = [x['left'] for x in list(cheek_surface_var_buffer)[-10:]]\n",
    "    rv = [x['right'] for x in list(cheek_surface_var_buffer)[-10:]]\n",
    "    la = [x['left'] for x in list(cheek_surface_dir_buffer)[-10:]]\n",
    "    ra = [x['right'] for x in list(cheek_surface_dir_buffer)[-10:]]\n",
    "\n",
    "    vl = [np.mean(lv), np.std(lv), np.min(lv), np.max(lv)] if lv else [0]*4\n",
    "    vr = [np.mean(rv), np.std(rv), np.min(rv), np.max(rv)] if rv else [0]*4\n",
    "    dl = [np.mean(la), np.std(la)] if len(la) > 1 else [0, 0]\n",
    "    dr = [np.mean(ra), np.std(ra)] if len(ra) > 1 else [0, 0]\n",
    "\n",
    "    return {\n",
    "        'Cheek puff micro-expression variance mean': var,\n",
    "        'Cheek puff rapid changes count': rapid,\n",
    "        'Cheek raise (mean)': stats[0],\n",
    "        'Cheek raise (std)': stats[1],\n",
    "        'Cheek velocity (mean)': vel_stats[0],\n",
    "        'Cheek velocity (std)': vel_stats[1],\n",
    "        'Cheek frequency mean': freq,\n",
    "        'Cheek asymmetry (mean)': asym,\n",
    "\n",
    "        'Left surface vector magnitude mean': l['mean_mag'],\n",
    "        'Left surface variance (current)': l['var'],\n",
    "        'Left surface variance mean': vl[0],\n",
    "        'Left surface variance std': vl[1],\n",
    "        'Left surface variance min': vl[2],\n",
    "        'Left surface variance max': vl[3],\n",
    "        'Left surface dominant angle mean': dl[0],\n",
    "        'Left surface dominant angle std': dl[1],\n",
    "\n",
    "        'Right surface vector magnitude mean': r['mean_mag'],\n",
    "        'Right surface variance (current)': r['var'],\n",
    "        'Right surface variance mean': vr[0],\n",
    "        'Right surface variance std': vr[1],\n",
    "        'Right surface variance min': vr[2],\n",
    "        'Right surface variance max': vr[3],\n",
    "        'Right surface dominant angle mean': dr[0],\n",
    "        'Right surface dominant angle std': dr[1],\n",
    "    }\n",
    "\n",
    "# --- EYE ---\n",
    "def compute_eye_features(landmarks, prev_landmarks):\n",
    "    if landmarks is None: return {}\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    norm_landmarks = [np.array(lm) - nose_tip for lm in landmarks]\n",
    "\n",
    "    lu = (norm_landmarks[159][1] + norm_landmarks[158][1] + norm_landmarks[160][1]) / 3\n",
    "    ll = (norm_landmarks[145][1] + norm_landmarks[144][1] + norm_landmarks[153][1]) / 3\n",
    "    lw = abs(norm_landmarks[33][0] - norm_landmarks[133][0])\n",
    "    left_ratio = abs(lu - ll) / lw if lw > 0 else 0\n",
    "\n",
    "    ru = (norm_landmarks[386][1] + norm_landmarks[387][1] + norm_landmarks[385][1]) / 3\n",
    "    rl = (norm_landmarks[374][1] + norm_landmarks[373][1] + norm_landmarks[380][1]) / 3\n",
    "    rw = abs(norm_landmarks[362][0] - norm_landmarks[263][0])\n",
    "    right_ratio = abs(ru - rl) / rw if rw > 0 else 0\n",
    "\n",
    "    ratio = (left_ratio + right_ratio) / 2\n",
    "    eye_ratio_buffer.append(ratio)\n",
    "    stats = [np.mean(eye_ratio_buffer), np.std(eye_ratio_buffer)] if len(eye_ratio_buffer) > 1 else [0, 0]\n",
    "    vel = abs(ratio - eye_ratio_buffer[-2]) if len(eye_ratio_buffer) > 1 else 0\n",
    "    eye_vel_buffer.append(vel)\n",
    "    vel_stats = [np.mean(eye_vel_buffer), np.std(eye_vel_buffer)] if len(eye_vel_buffer) > 1 else [0, 0]\n",
    "    rapid = len(find_peaks(list(eye_vel_buffer), distance=2)[0]) if len(eye_vel_buffer) > 1 else 0\n",
    "    var = np.var(eye_ratio_buffer) if len(eye_ratio_buffer) > 1 else 0\n",
    "    blink = 1 if ratio < 0.1 else 0\n",
    "    blink_buffer.append(blink)\n",
    "    blink_rate = sum(blink_buffer) / len(blink_buffer) if blink_buffer else 0\n",
    "\n",
    "    surface = compute_surface_vectors_split(landmarks, prev_landmarks, left_eye_idx_surface, right_eye_idx_surface)\n",
    "    l, r = surface['left'], surface['right']\n",
    "    eye_surface_var_buffer.append({'left': l['var'], 'right': r['var']})\n",
    "    eye_surface_dir_buffer.append({'left': l['angle'], 'right': r['angle']})\n",
    "\n",
    "    lv = [x['left'] for x in list(eye_surface_var_buffer)[-10:]]\n",
    "    rv = [x['right'] for x in list(eye_surface_var_buffer)[-10:]]\n",
    "    la = [x['left'] for x in list(eye_surface_dir_buffer)[-10:]]\n",
    "    ra = [x['right'] for x in list(eye_surface_dir_buffer)[-10:]]\n",
    "\n",
    "    vl = [np.mean(lv), np.std(lv), np.min(lv), np.max(lv)] if lv else [0]*4\n",
    "    vr = [np.mean(rv), np.std(rv), np.min(rv), np.max(rv)] if rv else [0]*4\n",
    "    dl = [np.mean(la), np.std(la)] if len(la) > 1 else [0, 0]\n",
    "    dr = [np.mean(ra), np.std(ra)] if len(ra) > 1 else [0, 0]\n",
    "\n",
    "    return {\n",
    "        'Eye widening micro-expression variance mean': var,\n",
    "        'Eye widening rapid changes count': rapid,\n",
    "        'Eye ratio (mean)': stats[0],\n",
    "        'Eye ratio (std)': stats[1],\n",
    "        'Blink rate': blink_rate,\n",
    "        'Eye squint velocity (mean)': vel_stats[0],\n",
    "        'Eye squint velocity (std)': vel_stats[1],\n",
    "\n",
    "        'Left surface vector magnitude mean': l['mean_mag'],\n",
    "        'Left surface variance (current)': l['var'],\n",
    "        'Left surface variance mean': vl[0],\n",
    "        'Left surface variance std': vl[1],\n",
    "        'Left surface variance min': vl[2],\n",
    "        'Left surface variance max': vl[3],\n",
    "        'Left surface dominant angle mean': dl[0],\n",
    "        'Left surface dominant angle std': dl[1],\n",
    "\n",
    "        'Right surface vector magnitude mean': r['mean_mag'],\n",
    "        'Right surface variance (current)': r['var'],\n",
    "        'Right surface variance mean': vr[0],\n",
    "        'Right surface variance std': vr[1],\n",
    "        'Right surface variance min': vr[2],\n",
    "        'Right surface variance max': vr[3],\n",
    "        'Right surface dominant angle mean': dr[0],\n",
    "        'Right surface dominant angle std': dr[1],\n",
    "    }\n",
    "\n",
    "# --- JAW ---\n",
    "def compute_jaw_features(landmarks, prev_landmarks):\n",
    "    if landmarks is None: return {}\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    norm_landmarks = [np.array(lm) - nose_tip for lm in landmarks]\n",
    "\n",
    "    chin = norm_landmarks[152]\n",
    "    upper_jaw_ref = norm_landmarks[13]\n",
    "    jaw_open = np.linalg.norm(chin - upper_jaw_ref)\n",
    "    jaw_open_buffer.append(jaw_open)\n",
    "    jaw_open_stats = [np.mean(jaw_open_buffer), np.std(jaw_open_buffer), np.min(jaw_open_buffer), np.max(jaw_open_buffer)] if len(jaw_open_buffer) > 1 else [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    jaw_vel = abs(jaw_open - jaw_open_buffer[-2]) if len(jaw_open_buffer) > 1 else 0\n",
    "    jaw_vel_buffer.append(jaw_vel)\n",
    "    jaw_vel_stats = [np.mean(jaw_vel_buffer), np.std(jaw_vel_buffer)] if len(jaw_vel_buffer) > 1 else [0.0, 0.0]\n",
    "\n",
    "    left_jaw = norm_landmarks[136]\n",
    "    right_jaw = norm_landmarks[400]\n",
    "    jaw_asym = np.abs(left_jaw[0] - right_jaw[0])\n",
    "    jaw_asym_stats = [np.mean([jaw_asym]), np.std([jaw_asym]), np.max([jaw_asym])] if len(jaw_open_buffer) > 1 else [0.0, 0.0, 0.0]\n",
    "\n",
    "    rapid_count = len(find_peaks(list(jaw_vel_buffer), distance=2)[0]) if len(jaw_vel_buffer) > 1 else 0\n",
    "    sig_mov_count = sum(1 for v in jaw_vel_buffer if v > 0.001)\n",
    "\n",
    "    freq_mean = np.mean(np.abs(fft(list(jaw_open_buffer)))[:buffer_size//2]) if len(jaw_open_buffer) == buffer_size else 0.0\n",
    "    peak_freq = np.max(np.abs(fft(list(jaw_open_buffer)))[:buffer_size//2]) if len(jaw_open_buffer) == buffer_size else 0.0\n",
    "\n",
    "    surface = compute_surface_vectors_split(landmarks, prev_landmarks, left_jaw_idx_surface, right_jaw_idx_surface)\n",
    "    l, r = surface['left'], surface['right']\n",
    "    jaw_surface_var_buffer.append({'left': l['var'], 'right': r['var']})\n",
    "    jaw_surface_dir_buffer.append({'left': l['angle'], 'right': r['angle']})\n",
    "\n",
    "    lv = [x['left'] for x in list(jaw_surface_var_buffer)[-10:]]\n",
    "    rv = [x['right'] for x in list(jaw_surface_var_buffer)[-10:]]\n",
    "    la = [x['left'] for x in list(jaw_surface_dir_buffer)[-10:]]\n",
    "    ra = [x['right'] for x in list(jaw_surface_dir_buffer)[-10:]]\n",
    "\n",
    "    vl = [np.mean(lv), np.std(lv), np.min(lv), np.max(lv)] if lv else [0]*4\n",
    "    vr = [np.mean(rv), np.std(rv), np.min(rv), np.max(rv)] if rv else [0]*4\n",
    "    dl = [np.mean(la), np.std(la)] if len(la) > 1 else [0, 0]\n",
    "    dr = [np.mean(ra), np.std(ra)] if len(ra) > 1 else [0, 0]\n",
    "\n",
    "    return {\n",
    "        'Jaw opening (mean)': jaw_open_stats[0],\n",
    "        'Jaw opening (std)': jaw_open_stats[1],\n",
    "        'Jaw opening (min)': jaw_open_stats[2],\n",
    "        'Jaw opening (max)': jaw_open_stats[3],\n",
    "        'Jaw velocity (mean)': jaw_vel_stats[0],\n",
    "        'Jaw velocity (std)': jaw_vel_stats[1],\n",
    "        'Jaw asymmetry (mean)': jaw_asym_stats[0],\n",
    "        'Jaw asymmetry (std)': jaw_asym_stats[1],\n",
    "        'Jaw asymmetry (max)': jaw_asym_stats[2],\n",
    "        'Jaw rapid changes count': rapid_count,\n",
    "        'Jaw significant movements count': sig_mov_count,\n",
    "        'Jaw frequency mean': freq_mean,\n",
    "        'Jaw peak frequency': peak_freq,\n",
    "\n",
    "        'Left surface vector magnitude mean': l['mean_mag'],\n",
    "        'Left surface variance (current)': l['var'],\n",
    "        'Left surface variance mean': vl[0],\n",
    "        'Left surface variance std': vl[1],\n",
    "        'Left surface variance min': vl[2],\n",
    "        'Left surface variance max': vl[3],\n",
    "        'Left surface dominant angle mean': dl[0],\n",
    "        'Left surface dominant angle std': dl[1],\n",
    "\n",
    "        'Right surface vector magnitude mean': r['mean_mag'],\n",
    "        'Right surface variance (current)': r['var'],\n",
    "        'Right surface variance mean': vr[0],\n",
    "        'Right surface variance std': vr[1],\n",
    "        'Right surface variance min': vr[2],\n",
    "        'Right surface variance max': vr[3],\n",
    "        'Right surface dominant angle mean': dr[0],\n",
    "        'Right surface dominant angle std': dr[1],\n",
    "    }\n",
    "\n",
    "# --- LIPS ---\n",
    "def compute_lips_features(landmarks, prev_landmarks):\n",
    "    if landmarks is None: return {}\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    norm_landmarks = [np.array(lm) - nose_tip for lm in landmarks]\n",
    "\n",
    "    upper_lip = norm_landmarks[13]\n",
    "    lower_lip = norm_landmarks[14]\n",
    "    lip_open = np.linalg.norm(upper_lip - lower_lip)\n",
    "    lips_open_buffer.append(lip_open)\n",
    "    lip_open_stats = [np.mean(lips_open_buffer), np.std(lips_open_buffer), np.min(lips_open_buffer), np.max(lips_open_buffer)] if len(lips_open_buffer) > 1 else [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    lip_vel = abs(lip_open - lips_open_buffer[-2]) if len(lips_open_buffer) > 1 else 0\n",
    "    lips_vel_buffer.append(lip_vel)\n",
    "    lip_vel_stats = [np.mean(lips_vel_buffer), np.std(lips_vel_buffer)] if len(lips_vel_buffer) > 1 else [0.0, 0.0]\n",
    "\n",
    "    micro_var = np.var(lips_open_buffer) if len(lips_open_buffer) > 1 else 0.0\n",
    "    rapid_count = len(find_peaks(list(lips_vel_buffer), distance=2)[0]) if len(lips_vel_buffer) > 1 else 0\n",
    "    sig_mov_count = sum(1 for v in lips_vel_buffer if v > 0.001)\n",
    "\n",
    "    freq_mean = np.mean(np.abs(fft(list(lips_open_buffer)))[:buffer_size//2]) if len(lips_open_buffer) == buffer_size else 0.0\n",
    "    peak_freq = np.max(np.abs(fft(list(lips_open_buffer)))[:buffer_size//2]) if len(lips_open_buffer) == buffer_size else 0.0\n",
    "\n",
    "    left_corner_y = norm_landmarks[61][1] - norm_landmarks[17][1]\n",
    "    right_corner_y = norm_landmarks[291][1] - norm_landmarks[17][1]\n",
    "    corner_asym = np.abs(left_corner_y - right_corner_y)\n",
    "    corner_asym_stats = [np.mean([corner_asym]), np.std([corner_asym]), np.max([corner_asym])] if len(lips_open_buffer) > 1 else [0.0, 0.0, 0.0]\n",
    "\n",
    "    surface = compute_surface_vectors_split(landmarks, prev_landmarks, left_lip_idx_surface, right_lip_idx_surface)\n",
    "    l, r = surface['left'], surface['right']\n",
    "    lips_surface_var_buffer.append({'left': l['var'], 'right': r['var']})\n",
    "    lips_surface_dir_buffer.append({'left': l['angle'], 'right': r['angle']})\n",
    "\n",
    "    lv = [x['left'] for x in list(lips_surface_var_buffer)[-10:]]\n",
    "    rv = [x['right'] for x in list(lips_surface_var_buffer)[-10:]]\n",
    "    la = [x['left'] for x in list(lips_surface_dir_buffer)[-10:]]\n",
    "    ra = [x['right'] for x in list(lips_surface_dir_buffer)[-10:]]\n",
    "\n",
    "    vl = [np.mean(lv), np.std(lv), np.min(lv), np.max(lv)] if lv else [0]*4\n",
    "    vr = [np.mean(rv), np.std(rv), np.min(rv), np.max(rv)] if rv else [0]*4\n",
    "    dl = [np.mean(la), np.std(la)] if len(la) > 1 else [0, 0]\n",
    "    dr = [np.mean(ra), np.std(ra)] if len(ra) > 1 else [0, 0]\n",
    "\n",
    "    return {\n",
    "        'Lip micro-expression variance mean': micro_var,\n",
    "        'Lip micro-expression rapid changes count': rapid_count,\n",
    "        'Lip opening (mean)': lip_open_stats[0],\n",
    "        'Lip opening (std)': lip_open_stats[1],\n",
    "        'Lip opening (min)': lip_open_stats[2],\n",
    "        'Lip opening (max)': lip_open_stats[3],\n",
    "        'Lip velocity (mean)': lip_vel_stats[0],\n",
    "        'Lip velocity (std)': lip_vel_stats[1],\n",
    "        'Lip significant movements count': sig_mov_count,\n",
    "        'Lip frequency mean': freq_mean,\n",
    "        'Lip peak frequency': peak_freq,\n",
    "        'Lip corner asymmetry (mean)': corner_asym_stats[0],\n",
    "        'Lip corner asymmetry (std)': corner_asym_stats[1],\n",
    "        'Lip corner asymmetry (max)': corner_asym_stats[2],\n",
    "\n",
    "        'Left surface vector magnitude mean': l['mean_mag'],\n",
    "        'Left surface variance (current)': l['var'],\n",
    "        'Left surface variance mean': vl[0],\n",
    "        'Left surface variance std': vl[1],\n",
    "        'Left surface variance min': vl[2],\n",
    "        'Left surface variance max': vl[3],\n",
    "        'Left surface dominant angle mean': dl[0],\n",
    "        'Left surface dominant angle std': dl[1],\n",
    "\n",
    "        'Right surface vector magnitude mean': r['mean_mag'],\n",
    "        'Right surface variance (current)': r['var'],\n",
    "        'Right surface variance mean': vr[0],\n",
    "        'Right surface variance std': vr[1],\n",
    "        'Right surface variance min': vr[2],\n",
    "        'Right surface variance max': vr[3],\n",
    "        'Right surface dominant angle mean': dr[0],\n",
    "        'Right surface dominant angle std': dr[1],\n",
    "    }\n",
    "\n",
    "# --- MOUTH ---\n",
    "def compute_mouth_features(landmarks, prev_landmarks):\n",
    "    if landmarks is None: return {}\n",
    "    nose_tip = np.array(landmarks[1])\n",
    "    norm_landmarks = [np.array(lm) - nose_tip for lm in landmarks]\n",
    "\n",
    "    upper_lip = norm_landmarks[13]\n",
    "    lower_lip = norm_landmarks[14]\n",
    "    mouth_open = np.linalg.norm(upper_lip - lower_lip)\n",
    "    mouth_open_buffer.append(mouth_open)\n",
    "    mouth_open_stats = [np.mean(mouth_open_buffer), np.std(mouth_open_buffer), np.min(mouth_open_buffer), np.max(mouth_open_buffer)] if len(mouth_open_buffer) > 1 else [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    mouth_vel = abs(mouth_open - mouth_open_buffer[-2]) if len(mouth_open_buffer) > 1 else 0\n",
    "    mouth_vel_buffer.append(mouth_vel)\n",
    "    mouth_vel_stats = [np.mean(mouth_vel_buffer), np.std(mouth_vel_buffer)] if len(mouth_vel_buffer) > 1 else [0.0, 0.0]\n",
    "\n",
    "    micro_var = np.var(mouth_open_buffer) if len(mouth_open_buffer) > 1 else 0.0\n",
    "    rapid_count = len(find_peaks(list(mouth_vel_buffer), distance=2)[0]) if len(mouth_vel_buffer) > 1 else 0\n",
    "    sig_mov_count = sum(1 for v in mouth_vel_buffer if v > 0.001)\n",
    "\n",
    "    freq_mean = np.mean(np.abs(fft(list(mouth_open_buffer)))[:buffer_size//2]) if len(mouth_open_buffer) == buffer_size else 0.0\n",
    "    peak_freq = np.max(np.abs(fft(list(mouth_open_buffer)))[:buffer_size//2]) if len(mouth_open_buffer) == buffer_size else 0.0\n",
    "\n",
    "    left_corner_y = norm_landmarks[61][1] - norm_landmarks[17][1]\n",
    "    right_corner_y = norm_landmarks[291][1] - norm_landmarks[17][1]\n",
    "    corner_asym = np.abs(left_corner_y - right_corner_y)\n",
    "    corner_asym_stats = [np.mean([corner_asym]), np.std([corner_asym]), np.max([corner_asym])] if len(mouth_open_buffer) > 1 else [0.0, 0.0, 0.0]\n",
    "\n",
    "    surface = compute_surface_vectors_split(landmarks, prev_landmarks, left_mouth_idx_surface, right_mouth_idx_surface)\n",
    "    l, r = surface['left'], surface['right']\n",
    "    mouth_surface_var_buffer.append({'left': l['var'], 'right': r['var']})\n",
    "    mouth_surface_dir_buffer.append({'left': l['angle'], 'right': r['angle']})\n",
    "\n",
    "    lv = [x['left'] for x in list(mouth_surface_var_buffer)[-10:]]\n",
    "    rv = [x['right'] for x in list(mouth_surface_var_buffer)[-10:]]\n",
    "    la = [x['left'] for x in list(mouth_surface_dir_buffer)[-10:]]\n",
    "    ra = [x['right'] for x in list(mouth_surface_dir_buffer)[-10:]]\n",
    "\n",
    "    vl = [np.mean(lv), np.std(lv), np.min(lv), np.max(lv)] if lv else [0]*4\n",
    "    vr = [np.mean(rv), np.std(rv), np.min(rv), np.max(rv)] if rv else [0]*4\n",
    "    dl = [np.mean(la), np.std(la)] if len(la) > 1 else [0, 0]\n",
    "    dr = [np.mean(ra), np.std(ra)] if len(ra) > 1 else [0, 0]\n",
    "\n",
    "    return {\n",
    "        'Mouth micro-expression variance mean': micro_var,\n",
    "        'Mouth micro-expression rapid changes count': rapid_count,\n",
    "        'Mouth opening (mean)': mouth_open_stats[0],\n",
    "        'Mouth opening (std)': mouth_open_stats[1],\n",
    "        'Mouth opening (min)': mouth_open_stats[2],\n",
    "        'Mouth opening (max)': mouth_open_stats[3],\n",
    "        'Mouth velocity (mean)': mouth_vel_stats[0],\n",
    "        'Mouth velocity (std)': mouth_vel_stats[1],\n",
    "        'Mouth significant movements count': sig_mov_count,\n",
    "        'Mouth frequency mean': freq_mean,\n",
    "        'Mouth peak frequency': peak_freq,\n",
    "        'Mouth corner asymmetry (mean)': corner_asym_stats[0],\n",
    "        'Mouth corner asymmetry (std)': corner_asym_stats[1],\n",
    "        'Mouth corner asymmetry (max)': corner_asym_stats[2],\n",
    "\n",
    "        'Left surface vector magnitude mean': l['mean_mag'],\n",
    "        'Left surface variance (current)': l['var'],\n",
    "        'Left surface variance mean': vl[0],\n",
    "        'Left surface variance std': vl[1],\n",
    "        'Left surface variance min': vl[2],\n",
    "        'Left surface variance max': vl[3],\n",
    "        'Left surface dominant angle mean': dl[0],\n",
    "        'Left surface dominant angle std': dl[1],\n",
    "\n",
    "        'Right surface vector magnitude mean': r['mean_mag'],\n",
    "        'Right surface variance (current)': r['var'],\n",
    "        'Right surface variance mean': vr[0],\n",
    "        'Right surface variance std': vr[1],\n",
    "        'Right surface variance min': vr[2],\n",
    "        'Right surface variance max': vr[3],\n",
    "        'Right surface dominant angle mean': dr[0],\n",
    "        'Right surface dominant angle std': dr[1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0922bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Video Processing (not used in training, but included for completeness) ---\n",
    "def process_video():\n",
    "    global frame_global, features_global, prev_landmarks_global\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    prev_landmarks = None\n",
    "\n",
    "    region_configs = [\n",
    "        ('Brow', left_brow_idx_surface, right_brow_idx_surface, (0, 255, 0)),\n",
    "        ('Cheek', left_cheek_idx_surface, right_cheek_idx_surface, (255, 0, 0)),\n",
    "        ('Eye', left_eye_idx_surface, right_eye_idx_surface, (0, 0, 255)),\n",
    "        ('Jaw', left_jaw_idx_surface, right_jaw_idx_surface, (255, 255, 0)),\n",
    "        ('Lips', left_lip_idx_surface, right_lip_idx_surface, (255, 0, 255)),\n",
    "        ('Mouth', left_mouth_idx_surface, right_mouth_idx_surface, (0, 255, 255)),\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb)\n",
    "        landmarks = None\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            lmks = results.multi_face_landmarks[0].landmark\n",
    "            landmarks = [[lm.x, lm.y, lm.z] for lm in lmks]\n",
    "            h, w, _ = frame.shape\n",
    "            for idx in set(brow_landmarks_idx + cheek_landmarks_idx + eye_landmarks_idx + jaw_landmarks_idx + lip_landmarks_idx + mouth_landmarks_idx):\n",
    "                if idx < len(lmks):\n",
    "                    lm = lmks[idx]\n",
    "                    cv2.circle(frame, (int(lm.x * w), int(lm.y * h)), 2, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw arrows\n",
    "            for name, l_idx, r_idx, color in region_configs:\n",
    "                data = compute_surface_vectors_split(landmarks, prev_landmarks, l_idx, r_idx)\n",
    "                for side_key, side_data in [('left', data['left']), ('right', data['right'])]:\n",
    "                    positions = side_data['positions']\n",
    "                    mean_mag = side_data['mean_mag']\n",
    "                    angle = side_data['angle']\n",
    "\n",
    "                    if len(positions) == 0 or mean_mag < 0.0008:\n",
    "                        continue\n",
    "\n",
    "                    # Compute average direction vector from angle\n",
    "                    avg_dir = np.array([np.cos(angle), np.sin(angle)])\n",
    "\n",
    "                    # Compute center position\n",
    "                    center_pos = np.mean(positions, axis=0) if positions else np.array([0, 0, 0])\n",
    "                    center_x = int(center_pos[0] * w)\n",
    "                    center_y = int(center_pos[1] * h)\n",
    "\n",
    "                    # Scale arrow length\n",
    "                    base_scale = 20\n",
    "                    max_length = 25\n",
    "                    min_length = 3\n",
    "                    arrow_length = min(max(mean_mag * w * base_scale * 30, min_length), max_length)\n",
    "\n",
    "                    dx = avg_dir[0] * arrow_length\n",
    "                    dy = avg_dir[1] * arrow_length\n",
    "\n",
    "                    end_x = int(center_x + dx)\n",
    "                    end_y = int(center_y + dy)\n",
    "\n",
    "                    # Draw the arrow\n",
    "                    cv2.arrowedLine(frame, (center_x, center_y), (end_x, end_y), color, 1, tipLength=0.25)\n",
    "\n",
    "                    # Label\n",
    "                    label = name[0] + ('L' if side_key == 'left' else 'R')\n",
    "                    cv2.putText(frame, label, (center_x - 20, center_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Compute features\n",
    "        features_global.update({\n",
    "            'Brow': compute_brow_features(landmarks, prev_landmarks),\n",
    "            'Cheek': compute_cheek_features(landmarks, prev_landmarks),\n",
    "            'Eye': compute_eye_features(landmarks, prev_landmarks),\n",
    "            'Jaw': compute_jaw_features(landmarks, prev_landmarks),\n",
    "            'Lips': compute_lips_features(landmarks, prev_landmarks),\n",
    "            'Mouth': compute_mouth_features(landmarks, prev_landmarks),\n",
    "        })\n",
    "\n",
    "        prev_landmarks = landmarks\n",
    "        frame_global = frame.copy()\n",
    "        time.sleep(0.03)\n",
    "\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aeedfdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reset Buffers ---\n",
    "def reset_buffers():\n",
    "    global brow_raise_buffer, brow_left_raise_buffer, brow_right_raise_buffer, brow_inner_raise_buffer, brow_vel_buffer, brow_surface_var_buffer, brow_surface_dir_buffer\n",
    "    global cheek_raise_buffer, cheek_vel_buffer, cheek_surface_var_buffer, cheek_surface_dir_buffer\n",
    "    global eye_ratio_buffer, eye_vel_buffer, blink_buffer, eye_surface_var_buffer, eye_surface_dir_buffer\n",
    "    global jaw_open_buffer, jaw_vel_buffer, jaw_surface_var_buffer, jaw_surface_dir_buffer\n",
    "    global lips_open_buffer, lips_vel_buffer, lips_surface_var_buffer, lips_surface_dir_buffer\n",
    "    global mouth_open_buffer, mouth_vel_buffer, mouth_surface_var_buffer, mouth_surface_dir_buffer\n",
    "\n",
    "    buffer_size = 10\n",
    "    brow_raise_buffer = deque(maxlen=buffer_size)\n",
    "    brow_left_raise_buffer = deque(maxlen=buffer_size)\n",
    "    brow_right_raise_buffer = deque(maxlen=buffer_size)\n",
    "    brow_inner_raise_buffer = deque(maxlen=buffer_size)\n",
    "    brow_vel_buffer = deque(maxlen=buffer_size)\n",
    "    brow_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "    brow_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    cheek_raise_buffer = deque(maxlen=buffer_size)\n",
    "    cheek_vel_buffer = deque(maxlen=buffer_size)\n",
    "    cheek_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "    cheek_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    eye_ratio_buffer = deque(maxlen=buffer_size)\n",
    "    eye_vel_buffer = deque(maxlen=buffer_size)\n",
    "    blink_buffer = deque(maxlen=30)\n",
    "    eye_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "    eye_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    jaw_open_buffer = deque(maxlen=buffer_size)\n",
    "    jaw_vel_buffer = deque(maxlen=buffer_size)\n",
    "    jaw_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "    jaw_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    lips_open_buffer = deque(maxlen=buffer_size)\n",
    "    lips_vel_buffer = deque(maxlen=buffer_size)\n",
    "    lips_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "    lips_surface_dir_buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    mouth_open_buffer = deque(maxlen=buffer_size)\n",
    "    mouth_vel_buffer = deque(maxlen=buffer_size)\n",
    "    mouth_surface_var_buffer = deque(maxlen=buffer_size)\n",
    "    mouth_surface_dir_buffer = deque(maxlen=buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd0ba3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return []\n",
    "\n",
    "    # Re-initialize FaceMesh with lower thresholds for better detection\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.1,  # Lowered from 0.3\n",
    "        min_tracking_confidence=0.1    # Lowered from 0.5\n",
    "    )\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video at {video_path}\")\n",
    "        return []\n",
    "\n",
    "    features_list = []\n",
    "    frame_count = 0\n",
    "    detected_count = 0\n",
    "    prev_landmarks = None  # Assuming this is used in your feature computation\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "        # Process frame\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            detected_count += 1\n",
    "            landmarks = [(lm.x, lm.y, lm.z) for lm in results.multi_face_landmarks[0].landmark]\n",
    "            \n",
    "            # Compute features (assuming your compute_*_features functions are defined)\n",
    "            brow_features = compute_brow_features(landmarks, prev_landmarks)\n",
    "            cheek_features = compute_cheek_features(landmarks, prev_landmarks)\n",
    "            eye_features = compute_eye_features(landmarks, prev_landmarks)\n",
    "            jaw_features = compute_jaw_features(landmarks, prev_landmarks)\n",
    "            lips_features = compute_lips_features(landmarks, prev_landmarks)\n",
    "            mouth_features = compute_mouth_features(landmarks, prev_landmarks)\n",
    "            \n",
    "            features = {\n",
    "                'Brow': brow_features,\n",
    "                'Cheek': cheek_features,\n",
    "                'Eye': eye_features,\n",
    "                'Jaw': jaw_features,\n",
    "                'Lips': lips_features,\n",
    "                'Mouth': mouth_features\n",
    "            }\n",
    "            features_list.append(features)\n",
    "            prev_landmarks = landmarks  # Update for next frame\n",
    "        else:\n",
    "            if frame_count % 50 == 0:  # Print occasionally to avoid spam\n",
    "                print(f\"Warning: No face detected in frame {frame_count}\")\n",
    "\n",
    "    cap.release()\n",
    "    face_mesh.close()\n",
    "\n",
    "    print(f\"Processed {frame_count} frames.\")\n",
    "    print(f\"Detected faces in {detected_count} frames ({(detected_count / frame_count * 100 if frame_count > 0 else 0):.2f}%).\")\n",
    "    \n",
    "    if detected_count == 0:\n",
    "        print(\"Tip: If no detections, try a different video, check lighting/angle, or further lower confidence thresholds.\")\n",
    "    \n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dee8c1",
   "metadata": {},
   "source": [
    "### This function takes the nested dictionary of facial features (produced by your MediaPipe-based feature extraction) and converts it into a single flat 1D NumPy array (a vector of numbers). This flat vector is what your PyTorch CNN+LSTM model needs as input for each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9351631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Flatten Features ---\n",
    "def flatten_features(features):\n",
    "    flat = []\n",
    "    for region in ['Brow', 'Cheek', 'Eye', 'Jaw', 'Lips', 'Mouth']:\n",
    "        if region in features:\n",
    "            for v in features[region].values():\n",
    "                flat.append(float(v))  # Ensure float\n",
    "    return np.array(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c6bf440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Dataset ---\n",
    "data_dir = 'expressions'\n",
    "labels = ['Angry', 'Calm', 'Disgust', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Surprised']\n",
    "X = []\n",
    "y = []\n",
    "lengths = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4680900",
   "metadata": {},
   "source": [
    "### This section of responsible for loading all the videos from your dataset folder, extracting facial features from each video using MediaPipe, converting them into sequences of flat vectors, and building the training data (X and y) for your PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8615292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 132 frames.\n",
      "Detected faces in 132 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 131 frames.\n",
      "Detected faces in 131 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 131 frames.\n",
      "Detected faces in 131 frames (100.00%).\n",
      "Processed 130 frames.\n",
      "Detected faces in 130 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 132 frames.\n",
      "Detected faces in 132 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 134 frames.\n",
      "Detected faces in 134 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 128 frames.\n",
      "Detected faces in 128 frames (100.00%).\n",
      "Processed 130 frames.\n",
      "Detected faces in 130 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 143 frames.\n",
      "Detected faces in 143 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 134 frames.\n",
      "Detected faces in 134 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 131 frames.\n",
      "Detected faces in 131 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 95 frames.\n",
      "Detected faces in 95 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 142 frames.\n",
      "Detected faces in 142 frames (100.00%).\n",
      "Processed 134 frames.\n",
      "Detected faces in 134 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 133 frames.\n",
      "Detected faces in 133 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 138 frames.\n",
      "Detected faces in 138 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 135 frames.\n",
      "Detected faces in 135 frames (100.00%).\n",
      "Processed 138 frames.\n",
      "Detected faces in 138 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 138 frames.\n",
      "Detected faces in 138 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 130 frames.\n",
      "Detected faces in 130 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 129 frames.\n",
      "Detected faces in 129 frames (100.00%).\n",
      "Processed 128 frames.\n",
      "Detected faces in 128 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 129 frames.\n",
      "Detected faces in 129 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 126 frames.\n",
      "Detected faces in 126 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 95 frames.\n",
      "Detected faces in 95 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 144 frames.\n",
      "Detected faces in 144 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 128 frames.\n",
      "Detected faces in 128 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 130 frames.\n",
      "Detected faces in 130 frames (100.00%).\n",
      "Processed 128 frames.\n",
      "Detected faces in 128 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 140 frames.\n",
      "Detected faces in 140 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 143 frames.\n",
      "Detected faces in 143 frames (100.00%).\n",
      "Processed 143 frames.\n",
      "Detected faces in 143 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 130 frames.\n",
      "Detected faces in 130 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 132 frames.\n",
      "Detected faces in 132 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 136 frames.\n",
      "Detected faces in 136 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 135 frames.\n",
      "Detected faces in 135 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 134 frames.\n",
      "Detected faces in 134 frames (100.00%).\n",
      "Processed 157 frames.\n",
      "Detected faces in 157 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 139 frames.\n",
      "Detected faces in 139 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 95 frames.\n",
      "Detected faces in 95 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 131 frames.\n",
      "Detected faces in 131 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 149 frames.\n",
      "Detected faces in 149 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 126 frames.\n",
      "Detected faces in 126 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 130 frames.\n",
      "Detected faces in 130 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 93 frames.\n",
      "Detected faces in 93 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 129 frames.\n",
      "Detected faces in 129 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 120 frames.\n",
      "Detected faces in 120 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 132 frames.\n",
      "Detected faces in 132 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 121 frames.\n",
      "Detected faces in 121 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 129 frames.\n",
      "Detected faces in 129 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 95 frames.\n",
      "Detected faces in 95 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 95 frames.\n",
      "Detected faces in 95 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 126 frames.\n",
      "Detected faces in 126 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 129 frames.\n",
      "Detected faces in 129 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 138 frames.\n",
      "Detected faces in 138 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 117 frames.\n",
      "Detected faces in 117 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 125 frames.\n",
      "Detected faces in 125 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 128 frames.\n",
      "Detected faces in 128 frames (100.00%).\n",
      "Processed 132 frames.\n",
      "Detected faces in 132 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 127 frames.\n",
      "Detected faces in 127 frames (100.00%).\n",
      "Processed 128 frames.\n",
      "Detected faces in 128 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 131 frames.\n",
      "Detected faces in 131 frames (100.00%).\n",
      "Processed 137 frames.\n",
      "Detected faces in 137 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 91 frames.\n",
      "Detected faces in 91 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 92 frames.\n",
      "Detected faces in 92 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 114 frames.\n",
      "Detected faces in 114 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 94 frames.\n",
      "Detected faces in 94 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 103 frames.\n",
      "Detected faces in 103 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 104 frames.\n",
      "Detected faces in 104 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 124 frames.\n",
      "Detected faces in 124 frames (100.00%).\n",
      "Processed 96 frames.\n",
      "Detected faces in 96 frames (100.00%).\n",
      "Processed 116 frames.\n",
      "Detected faces in 116 frames (100.00%).\n",
      "Processed 115 frames.\n",
      "Detected faces in 115 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 92 frames.\n",
      "Detected faces in 92 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 122 frames.\n",
      "Detected faces in 122 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 105 frames.\n",
      "Detected faces in 105 frames (100.00%).\n",
      "Processed 118 frames.\n",
      "Detected faces in 118 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 113 frames.\n",
      "Detected faces in 113 frames (100.00%).\n",
      "Processed 108 frames.\n",
      "Detected faces in 108 frames (100.00%).\n",
      "Processed 107 frames.\n",
      "Detected faces in 107 frames (100.00%).\n",
      "Processed 123 frames.\n",
      "Detected faces in 123 frames (100.00%).\n",
      "Processed 100 frames.\n",
      "Detected faces in 100 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Processed 93 frames.\n",
      "Detected faces in 93 frames (100.00%).\n",
      "Processed 111 frames.\n",
      "Detected faces in 111 frames (100.00%).\n",
      "Processed 99 frames.\n",
      "Detected faces in 99 frames (100.00%).\n",
      "Processed 110 frames.\n",
      "Detected faces in 110 frames (100.00%).\n",
      "Processed 98 frames.\n",
      "Detected faces in 98 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 106 frames.\n",
      "Detected faces in 106 frames (100.00%).\n",
      "Processed 138 frames.\n",
      "Detected faces in 138 frames (100.00%).\n",
      "Processed 97 frames.\n",
      "Detected faces in 97 frames (100.00%).\n",
      "Processed 109 frames.\n",
      "Detected faces in 109 frames (100.00%).\n",
      "Processed 112 frames.\n",
      "Detected faces in 112 frames (100.00%).\n",
      "Processed 101 frames.\n",
      "Detected faces in 101 frames (100.00%).\n",
      "Processed 119 frames.\n",
      "Detected faces in 119 frames (100.00%).\n"
     ]
    }
   ],
   "source": [
    "# --- Load Dataset ---\n",
    "data_dir = 'expressions'\n",
    "labels = ['Angry', 'Calm', 'Disgust', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Surprised']\n",
    "X = []\n",
    "y = []\n",
    "lengths = []  \n",
    "\n",
    "for label_idx, label in enumerate(labels):\n",
    "    subdir = os.path.join(data_dir, label)\n",
    "    if os.path.isdir(subdir):\n",
    "        for vid in os.listdir(subdir):\n",
    "            if vid.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "                path = os.path.join(subdir, vid)\n",
    "                features_list = extract_features_from_video(path)\n",
    "                if features_list:\n",
    "                    seq = [flatten_features(f) for f in features_list if f]\n",
    "                    if len(seq) > 0:\n",
    "                        X.append(seq)\n",
    "                        y.append(label_idx)\n",
    "                        lengths.append(len(seq))  # Store length\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"No videos found or processed.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d42bf7",
   "metadata": {},
   "source": [
    "### This prepares the variable-length video sequences (in X) so they can be batched together and fed efficiently into your PyTorch model (CNN+LSTM). Neural networks require all inputs in a batch to have the same shape, but your videos have different lengths (different number of frames). Padding solves this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13e206aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pad Sequences ---\n",
    "feature_dim = len(X[0][0]) if X and X[0] else 0\n",
    "X_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in X]\n",
    "X_padded = pad_sequence(X_tensors, batch_first=True)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "lengths = np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "adc422ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.9362, 0.9362, 0.9362, 0.9362, 0.9362, 1.9130, 0.9362, 0.9362])\n"
     ]
    }
   ],
   "source": [
    "# --- Split Train/Test ---\n",
    "num_samples = len(X)\n",
    "indices = np.arange(num_samples)\n",
    "np.random.shuffle(indices)\n",
    "train_size = int(0.8 * num_samples)\n",
    "train_idx = indices[:train_size]\n",
    "test_idx = indices[train_size:]\n",
    "\n",
    "X_train = X_padded[train_idx]\n",
    "y_train = y[train_idx]\n",
    "train_lengths = lengths[train_idx]\n",
    "\n",
    "X_test = X_padded[test_idx]\n",
    "y_test = y[test_idx]\n",
    "test_lengths = lengths[test_idx]\n",
    "\n",
    "# --- Compute Class Weights for Imbalance ---\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y.numpy()), y=y.numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc8b7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lengths to torch tensors\n",
    "train_lengths = torch.tensor(train_lengths, dtype=torch.long)\n",
    "test_lengths = torch.tensor(test_lengths, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ebdaa1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Normalize Features (FIXED) ---\n",
    "# Step 1: Fit scaler only on real frames (exclude padding)\n",
    "# X_train is (num_samples, max_seq_len, feature_dim)\n",
    "train_numpy = X_train.numpy()  # shape: (N, T, F)\n",
    "real_frames_list = []\n",
    "for i in range(len(train_numpy)):\n",
    "    length = train_lengths[i].item()\n",
    "    real_frames_list.append(train_numpy[i, :length, :])  # take only actual frames\n",
    "\n",
    "# Concatenate all real frames  (total_real_frames, feature_dim)\n",
    "all_train_frames = np.concatenate(real_frames_list, axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_train_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dadaef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete. Feature dim: 166\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Apply transform to full padded sequences\n",
    "def normalize_padded_sequences(padded_tensor):\n",
    "    \"\"\"Apply scaler to a padded 3D tensor (batch, seq, feat)\"\"\"\n",
    "    numpy_3d = padded_tensor.numpy()\n",
    "    N, T, F = numpy_3d.shape\n",
    "    # Reshape to 2D: (N*T, F)\n",
    "    flat_2d = numpy_3d.reshape(-1, F)\n",
    "    # Transform\n",
    "    transformed_2d = scaler.transform(flat_2d)\n",
    "    # Reshape back to 3D\n",
    "    transformed_3d = transformed_2d.reshape(N, T, F)\n",
    "    return torch.tensor(transformed_3d, dtype=torch.float32)\n",
    "\n",
    "X_train_norm = normalize_padded_sequences(X_train)\n",
    "X_test_norm = normalize_padded_sequences(X_test)\n",
    "\n",
    "print(f\"Normalization complete. Feature dim: {X_train_norm.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2da5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Attention Module ---\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim * 2)  # For bidirectional\n",
    "        self.v = nn.Linear(hidden_dim * 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # hidden_states: (batch, seq_len, hidden*2)\n",
    "        attn_weights = self.v(torch.tanh(self.attn(hidden_states)))\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        context = torch.sum(attn_weights * hidden_states, dim=1)\n",
    "        return context\n",
    "\n",
    "# --- Improved CNN+LSTM Model with Attention ---\n",
    "class ImprovedCNNLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=3, dropout=0.5):\n",
    "        super(ImprovedCNNLSTM, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 256, kernel_size=3, padding=1),  # Increased filters\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm = nn.LSTM(32, hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=True, dropout=dropout)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq, feat)  (batch, feat, seq)\n",
    "        x = self.cnn(x)         # (batch, 32, seq//4) due to pooling\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq//4, 32)\n",
    "\n",
    "        # Adjust lengths for pooling (divide by 4 due to two MaxPool1d layers)\n",
    "        adjusted_lengths = (lengths.cpu() // 4).clamp(min=1)\n",
    "        packed = pack_padded_sequence(x, adjusted_lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)  # (batch, seq//4, hidden*2)\n",
    "\n",
    "        attn_out = self.attention(lstm_out)  # (batch, hidden*2)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        return self.fc(attn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6849f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize Improved Model ---\n",
    "hidden_dim = 512  # Increased from 256\n",
    "num_classes = len(labels)\n",
    "model = ImprovedCNNLSTM(feature_dim, hidden_dim, num_classes, num_layers=3, dropout=0.5)\n",
    "\n",
    "# Use class-weighted loss to handle imbalance\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-3)  # Adjusted LR and weight decay\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150)  # T_max should match your epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1b5c0e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 | Loss: 1.7657 | Val Loss: 1.4520 | Val Acc: 41.13% | LR: 0.000500\n",
      "  >>> model saved!\n",
      "Epoch 2/150 | Loss: 1.6202 | Val Loss: 1.5663 | Val Acc: 36.17% | LR: 0.000500\n",
      "Epoch 3/150 | Loss: 1.5538 | Val Loss: 1.3506 | Val Acc: 44.68% | LR: 0.000499\n",
      "  >>> model saved!\n",
      "Epoch 4/150 | Loss: 1.5454 | Val Loss: 1.3279 | Val Acc: 43.26% | LR: 0.000499\n",
      "Epoch 5/150 | Loss: 1.4121 | Val Loss: 1.2450 | Val Acc: 47.52% | LR: 0.000498\n",
      "  >>> model saved!\n",
      "Epoch 6/150 | Loss: 1.4339 | Val Loss: 1.2964 | Val Acc: 46.10% | LR: 0.000497\n",
      "Epoch 7/150 | Loss: 1.3556 | Val Loss: 1.2971 | Val Acc: 48.23% | LR: 0.000496\n",
      "  >>> model saved!\n",
      "Epoch 8/150 | Loss: 1.3532 | Val Loss: 1.2929 | Val Acc: 44.68% | LR: 0.000496\n",
      "Epoch 9/150 | Loss: 1.2830 | Val Loss: 1.2467 | Val Acc: 57.45% | LR: 0.000495\n",
      "  >>> model saved!\n",
      "Epoch 10/150 | Loss: 1.1517 | Val Loss: 1.2129 | Val Acc: 51.06% | LR: 0.000493\n",
      "Epoch 11/150 | Loss: 1.0610 | Val Loss: 1.1525 | Val Acc: 58.87% | LR: 0.000492\n",
      "  >>> model saved!\n",
      "Epoch 12/150 | Loss: 1.1609 | Val Loss: 1.0611 | Val Acc: 61.70% | LR: 0.000491\n",
      "  >>> model saved!\n",
      "Epoch 13/150 | Loss: 1.0814 | Val Loss: 1.0836 | Val Acc: 58.87% | LR: 0.000489\n",
      "Epoch 14/150 | Loss: 1.0546 | Val Loss: 1.0096 | Val Acc: 62.41% | LR: 0.000488\n",
      "  >>> model saved!\n",
      "Epoch 15/150 | Loss: 1.0204 | Val Loss: 1.1199 | Val Acc: 62.41% | LR: 0.000486\n",
      "Epoch 16/150 | Loss: 0.9734 | Val Loss: 0.9594 | Val Acc: 63.83% | LR: 0.000484\n",
      "  >>> model saved!\n",
      "Epoch 17/150 | Loss: 0.9071 | Val Loss: 0.9926 | Val Acc: 65.96% | LR: 0.000482\n",
      "  >>> model saved!\n",
      "Epoch 18/150 | Loss: 0.8047 | Val Loss: 1.1022 | Val Acc: 67.38% | LR: 0.000480\n",
      "  >>> model saved!\n",
      "Epoch 19/150 | Loss: 0.8788 | Val Loss: 1.0119 | Val Acc: 59.57% | LR: 0.000478\n",
      "Epoch 20/150 | Loss: 0.8162 | Val Loss: 1.0450 | Val Acc: 59.57% | LR: 0.000476\n",
      "Epoch 21/150 | Loss: 0.8561 | Val Loss: 1.1891 | Val Acc: 60.28% | LR: 0.000474\n",
      "Epoch 22/150 | Loss: 0.7227 | Val Loss: 1.0098 | Val Acc: 68.09% | LR: 0.000472\n",
      "  >>> model saved!\n",
      "Epoch 23/150 | Loss: 0.6605 | Val Loss: 0.9106 | Val Acc: 68.79% | LR: 0.000469\n",
      "  >>> model saved!\n",
      "Epoch 24/150 | Loss: 0.7394 | Val Loss: 1.0255 | Val Acc: 71.63% | LR: 0.000467\n",
      "  >>> model saved!\n",
      "Epoch 25/150 | Loss: 0.7173 | Val Loss: 1.0191 | Val Acc: 67.38% | LR: 0.000464\n",
      "Epoch 26/150 | Loss: 0.6132 | Val Loss: 1.3662 | Val Acc: 58.16% | LR: 0.000461\n",
      "Epoch 27/150 | Loss: 0.5652 | Val Loss: 1.2221 | Val Acc: 60.99% | LR: 0.000458\n",
      "Epoch 28/150 | Loss: 0.5833 | Val Loss: 1.1024 | Val Acc: 61.70% | LR: 0.000455\n",
      "Epoch 29/150 | Loss: 0.5313 | Val Loss: 1.2996 | Val Acc: 63.12% | LR: 0.000452\n",
      "Epoch 30/150 | Loss: 0.5648 | Val Loss: 1.3585 | Val Acc: 61.70% | LR: 0.000449\n",
      "Epoch 31/150 | Loss: 0.5953 | Val Loss: 1.3729 | Val Acc: 63.12% | LR: 0.000446\n",
      "Epoch 32/150 | Loss: 0.3710 | Val Loss: 1.3098 | Val Acc: 63.12% | LR: 0.000443\n",
      "Epoch 33/150 | Loss: 0.4325 | Val Loss: 1.2373 | Val Acc: 66.67% | LR: 0.000439\n",
      "Epoch 34/150 | Loss: 0.4268 | Val Loss: 1.3236 | Val Acc: 67.38% | LR: 0.000436\n",
      "Epoch 35/150 | Loss: 0.4448 | Val Loss: 1.2391 | Val Acc: 65.25% | LR: 0.000432\n",
      "Epoch 36/150 | Loss: 0.3660 | Val Loss: 1.5880 | Val Acc: 63.83% | LR: 0.000429\n",
      "Epoch 37/150 | Loss: 0.3384 | Val Loss: 1.3173 | Val Acc: 65.96% | LR: 0.000425\n",
      "Epoch 38/150 | Loss: 0.3443 | Val Loss: 1.3844 | Val Acc: 65.25% | LR: 0.000421\n",
      "Epoch 39/150 | Loss: 0.3278 | Val Loss: 1.8529 | Val Acc: 60.28% | LR: 0.000417\n",
      "Early stopping triggered after 39 epochs\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop with Early Stopping ---\n",
    "epochs = 150  # Increased from 100\n",
    "batch_size = 8\n",
    "best_acc = 0.0\n",
    "patience = 15  # Increased patience\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    permutation = torch.randperm(len(X_train_norm))  # Shuffle batches\n",
    "\n",
    "    for i in range(0, len(X_train_norm), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_X = X_train_norm[indices]\n",
    "        batch_lengths = train_lengths[indices]\n",
    "        batch_y = y_train[indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X, batch_lengths)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / (len(X_train_norm) // batch_size)\n",
    "    scheduler.step()  # Updated for CosineAnnealingLR\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_test_norm, test_lengths)\n",
    "        val_loss = criterion(val_outputs, y_test).item()\n",
    "        val_pred = val_outputs.argmax(dim=1)\n",
    "        val_acc = (val_pred == y_test).float().mean().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}% | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # Save model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'landmark_facial_expression_model.pth')\n",
    "        print(\"  >>> model saved!\")\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d31f97c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 71.63%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.88      0.94      0.91        16\n",
      "        Calm       0.52      0.80      0.63        15\n",
      "     Disgust       0.64      0.70      0.67        23\n",
      "     Fearful       0.83      0.75      0.79        20\n",
      "       Happy       0.83      0.67      0.74        15\n",
      "     Neutral       0.80      0.86      0.83        14\n",
      "         Sad       0.67      0.29      0.40        21\n",
      "   Surprised       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.72       141\n",
      "   macro avg       0.73      0.73      0.72       141\n",
      "weighted avg       0.73      0.72      0.70       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Final Evaluation with Classification Report and Confusion Matrix ---\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model.load_state_dict(torch.load('landmark_facial_expression_model.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_norm, test_lengths)\n",
    "    test_pred = test_outputs.argmax(dim=1).cpu().numpy()\n",
    "    test_true = y_test.cpu().numpy()\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(test_true, test_pred)\n",
    "print(f\"Final Test Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_true, test_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8a2c6652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0  0  1  0  0]\n",
      " [ 0 12  0  0  1  1  1  0]\n",
      " [ 0  3 16  2  0  0  1  1]\n",
      " [ 2  0  1 15  0  0  0  2]\n",
      " [ 0  1  1  0 10  0  0  3]\n",
      " [ 0  1  0  0  0 12  1  0]\n",
      " [ 0  6  6  0  1  1  6  1]\n",
      " [ 0  0  1  1  0  0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_true, test_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f0507a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved as 'confusion_heatmap.png'\n"
     ]
    }
   ],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_heatmap.png')\n",
    "plt.show()\n",
    "print(\"Heatmap saved as 'confusion_heatmap.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3487ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on: testing\\Surprised\\01-01-08-01-01-01-13.mp4\n",
      "File exists: True\n",
      "Processed 102 frames.\n",
      "Detected faces in 102 frames (100.00%).\n",
      "Extracted features from 102 frames.\n",
      "Processed 102 valid feature vectors.\n",
      "\n",
      "==================================================\n",
      "PREDICTED EXPRESSION: SURPRISED\n",
      "Confidence: 90.78%\n",
      "==================================================\n",
      "\n",
      "Top 3 Predictions:\n",
      "  1. Surprised  : 90.78%\n",
      "  2. Angry      : 3.74%\n",
      "  3. Fearful    : 3.50%\n"
     ]
    }
   ],
   "source": [
    "# --- Test on a New Video ---\n",
    "test_video_path = os.path.join('testing', 'Surprised', '01-01-08-01-01-01-13.mp4')\n",
    "\n",
    "# Extract features from the video\n",
    "print(f\"Testing on: {test_video_path}\")\n",
    "print(f\"File exists: {os.path.exists(test_video_path)}\")\n",
    "\n",
    "features_list = extract_features_from_video(test_video_path)\n",
    "\n",
    "if not features_list or len(features_list) == 0:\n",
    "    print(\"No facial features detected in the video.\")\n",
    "else:\n",
    "    print(f\"Extracted features from {len(features_list)} frames.\")\n",
    "\n",
    "    # Flatten each frame's features into a vector\n",
    "    seq = []\n",
    "    for f in features_list:\n",
    "        flattened = flatten_features(f)\n",
    "        if flattened is not None:  # Safety check\n",
    "            seq.append(flattened)\n",
    "    \n",
    "    if len(seq) == 0:\n",
    "        print(\"No valid feature vectors after flattening.\")\n",
    "    else:\n",
    "        print(f\"Processed {len(seq)} valid feature vectors.\")\n",
    "\n",
    "        # Get max sequence length from training (assuming X_padded exists)\n",
    "        max_seq_len = X_padded.shape[1]\n",
    "        feature_dim = X_padded.shape[2]\n",
    "\n",
    "        # Create padded array: (1, max_seq_len, feature_dim)\n",
    "        padded_seq = np.zeros((1, max_seq_len, feature_dim), dtype=np.float32)\n",
    "        actual_length = min(len(seq), max_seq_len)\n",
    "        padded_seq[0, :actual_length, :] = seq[:actual_length]\n",
    "\n",
    "        # Convert to torch tensor\n",
    "        padded_tensor = torch.tensor(padded_seq, dtype=torch.float32)\n",
    "\n",
    "        # Normalize using the SAME scaler from training\n",
    "        test_tensor = normalize_padded_sequences(padded_tensor)  # This returns a torch tensor\n",
    "\n",
    "        # Length tensor\n",
    "        test_length = torch.tensor([actual_length], dtype=torch.long)\n",
    "\n",
    "        # Load best model and predict\n",
    "        model.load_state_dict(torch.load('landmark_facial_expression_model.pth'))\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(test_tensor, test_length)\n",
    "            probabilities = torch.softmax(output, dim=1)[0]\n",
    "            pred_idx = output.argmax(dim=1).item()\n",
    "            confidence = probabilities[pred_idx].item()\n",
    "\n",
    "            predicted_expression = labels[pred_idx]\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"PREDICTED EXPRESSION: {predicted_expression.upper()}\")\n",
    "        print(f\"Confidence: {confidence * 100:.2f}%\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Optional: Show top-3 predictions\n",
    "        print(\"\\nTop 3 Predictions:\")\n",
    "        topk_vals, topk_idx = torch.topk(probabilities, 3)\n",
    "        for i in range(3):\n",
    "            expr = labels[topk_idx[i]]\n",
    "            conf = topk_vals[i].item() * 100\n",
    "            print(f\"  {i+1}. {expr:<10} : {conf:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
